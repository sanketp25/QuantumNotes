{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZRaZ3GqDrxN",
        "outputId": "0236037d-f5c6-4307-d01c-6f5b13ad152f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.9.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: pysrt in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (1.1.2)\n",
            "Requirement already satisfied: webvtt-py in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.5.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (0.3.31)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (0.3.11)\n",
            "Requirement already satisfied: langchain-experimental in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (0.3.4)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (0.3.8)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (0.3.35)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.3.1)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (0.2.6)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (1.0.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 35)) (1.2.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (6.1.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 39)) (1.2.0)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 40)) (1.26.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 44)) (4.57.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.12/dist-packages (from faster-whisper->-r requirements.txt (line 7)) (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper->-r requirements.txt (line 7)) (0.35.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper->-r requirements.txt (line 7)) (0.22.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.12/dist-packages (from faster-whisper->-r requirements.txt (line 7)) (1.23.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper->-r requirements.txt (line 7)) (16.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 11)) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 11)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 11)) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (4.15.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from pysrt->-r requirements.txt (line 15)) (5.2.0)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (0.4.37)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (0.4.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 21)) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 21)) (25.0)\n",
            "Requirement already satisfied: groq<1,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq->-r requirements.txt (line 26)) (0.33.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r requirements.txt (line 27)) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r requirements.txt (line 27)) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 32)) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 32)) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 32)) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 32)) (3.6.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35)) (0.38.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (5.4.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.38.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.75.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (4.25.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx->-r requirements.txt (line 39)) (5.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.4.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 44)) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (1.22.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 35)) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 20)) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 20)) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq->-r requirements.txt (line 26)) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq->-r requirements.txt (line 26)) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq->-r requirements.txt (line 26)) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper->-r requirements.txt (line 7)) (1.1.10)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r requirements.txt (line 21)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 35)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 35)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 35)) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (0.10)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph->-r requirements.txt (line 32)) (1.11.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 19)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 19)) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7)) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai->-r requirements.txt (line 27)) (0.11.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 35)) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 35)) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 35)) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 35)) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 35)) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 35)) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 19)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 19)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 19)) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->-r requirements.txt (line 20)) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 19)) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 35)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 35)) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 19)) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 43)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 35)) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35)) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35)) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35)) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35)) (15.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 43)) (3.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 12)) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 35)) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 35)) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 20)) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7)) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "OtUlPaDZERfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# IMPORTS\n",
        "# ========================================\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import pathlib\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, TypedDict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Whisper and audio processing\n",
        "from faster_whisper import WhisperModel\n",
        "import ffmpeg\n",
        "\n",
        "# Text processing\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.schema import Document\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "# LLM\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# For subtitle parsing\n",
        "try:\n",
        "    import pysrt\n",
        "except ImportError:\n",
        "    print(\"pysrt not installed. SRT support will be limited.\")\n",
        "try:\n",
        "    import webvtt\n",
        "except ImportError:\n",
        "    print(\"webvtt-py not installed. VTT support will be limited.\")\n",
        "\n",
        "# Google Colab userdata (comment out if not using Colab)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Not running in Colab. Make sure to set environment variables manually.\")"
      ],
      "metadata": {
        "id": "6A4bElbjEL1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CONFIGURATION\n",
        "# ========================================\n",
        "WHISPER_MODEL = \"medium\"\n",
        "VIDEO_EXT = {\".mp4\", \".mkv\", \".mov\", \".avi\"}\n",
        "AUDIO_EXT = {\".wav\", \".mp3\", \".m4a\", \".flac\", \".aac\", \".ogg\"}\n",
        "TRANSCRIPT_EXT = {\".txt\", \".srt\", \".vtt\", \".json\"}\n",
        "CHUNK_SIZE = 1800\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "# Directory setup\n",
        "BASE = \".\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "os.makedirs(f\"{DATA}/audio\", exist_ok=True)\n",
        "os.makedirs(f\"{DATA}/transcripts\", exist_ok=True)\n",
        "os.makedirs(f\"{DATA}/chunks\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "RVuvuKuHEUQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Processor"
      ],
      "metadata": {
        "id": "YAE6a2ZNEfjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FILE PROCESSOR CLASS\n",
        "# ========================================\n",
        "class FileProcessor:\n",
        "    \"\"\"Handles file upload, format detection, and routing\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.whisper_model = None\n",
        "\n",
        "    def initialize_whisper(self):\n",
        "        \"\"\"Initialize Whisper model once\"\"\"\n",
        "        if self.whisper_model is None:\n",
        "            print(\"Initializing Whisper model...\")\n",
        "            self.whisper_model = WhisperModel(\n",
        "                WHISPER_MODEL,\n",
        "                device=\"cuda\",\n",
        "                compute_type=\"float16\"\n",
        "            )\n",
        "            gc.collect()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_file_stem(fname):\n",
        "        stem = pathlib.Path(fname).stem\n",
        "        # Sanitize the stem for use in collection names\n",
        "        import re\n",
        "        sanitized_stem = re.sub(r'[^a-zA-Z0-9._-]', '_', stem)\n",
        "        sanitized_stem = sanitized_stem.strip('_-.')  # removes leading/trailing invalid chars\n",
        "        if len(sanitized_stem) < 3:\n",
        "         sanitized_stem = f\"doc_{sanitized_stem}\"\n",
        "        return sanitized_stem\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_audio_duration(audio_path):\n",
        "        \"\"\"Get audio duration in seconds\"\"\"\n",
        "        try:\n",
        "            probe = ffmpeg.probe(audio_path)\n",
        "            return float(probe['format']['duration'])\n",
        "        except ffmpeg.Error as e:\n",
        "            print(f\"Error getting duration: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def extract_audio_from_video(self, video_path, out_audio_path, sr=16000):\n",
        "        \"\"\"Convert video to audio\"\"\"\n",
        "        if not os.path.exists(out_audio_path):\n",
        "            print(f\"Extracting audio from video: {video_path}\")\n",
        "            (\n",
        "                ffmpeg\n",
        "                .input(video_path)\n",
        "                .output(out_audio_path, ac=1, ar=sr, format='wav', loglevel=\"error\")\n",
        "                .overwrite_output()\n",
        "                .run()\n",
        "            )\n",
        "            print(f\"✓ Audio extracted: {out_audio_path}\")\n",
        "        return out_audio_path\n",
        "\n",
        "    def transcribe_audio(self, audio_path, doc_id):\n",
        "        \"\"\"Transcribe audio using Whisper\"\"\"\n",
        "        self.initialize_whisper()\n",
        "\n",
        "        print(f\"Transcribing audio: {audio_path}\")\n",
        "        segments, info = self.whisper_model.transcribe(\n",
        "            audio_path,\n",
        "            beam_size=5,\n",
        "            vad_filter=True,\n",
        "            word_timestamps=False\n",
        "        )\n",
        "\n",
        "        rows = []\n",
        "        for i, seg in enumerate(segments):\n",
        "            rows.append({\n",
        "                \"doc_id\": doc_id,\n",
        "                \"segment_idx\": i,\n",
        "                \"start_ts\": float(seg.start),\n",
        "                \"end_ts\": float(seg.end),\n",
        "                \"text\": seg.text.strip()\n",
        "            })\n",
        "\n",
        "        out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "        pd.DataFrame(rows).to_parquet(out_path, index=False)\n",
        "        print(f\"✓ Transcript saved: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    def process_video(self, video_path, doc_id):\n",
        "        \"\"\"Process video: extract audio, transcribe\"\"\"\n",
        "        print(f\"\\n=== Processing Video ===\")\n",
        "        audio_path = f\"{DATA}/audio/{doc_id}.wav\"\n",
        "        self.extract_audio_from_video(video_path, audio_path)\n",
        "\n",
        "        duration = self.get_audio_duration(audio_path)\n",
        "        if duration > 7200:  # 2 hours\n",
        "            print(f\"⚠ Warning: Audio is {duration/60:.1f} minutes. This may take a while.\")\n",
        "\n",
        "        return self.transcribe_audio(audio_path, doc_id)\n",
        "\n",
        "    def process_audio(self, audio_path, doc_id):\n",
        "        \"\"\"Process audio file directly\"\"\"\n",
        "        print(f\"\\n=== Processing Audio ===\")\n",
        "        ext = pathlib.Path(audio_path).suffix.lower()\n",
        "        dst = f\"{DATA}/audio/{doc_id}.wav\"\n",
        "\n",
        "        if ext == \".wav\":\n",
        "            shutil.copy(audio_path, dst)\n",
        "        else:\n",
        "            print(f\"Converting {ext} to WAV...\")\n",
        "            (\n",
        "                ffmpeg\n",
        "                .input(audio_path)\n",
        "                .output(dst, ac=1, ar=16000, format='wav', loglevel=\"error\")\n",
        "                .overwrite_output()\n",
        "                .run()\n",
        "            )\n",
        "\n",
        "        print(f\"✓ Audio ready: {dst}\")\n",
        "\n",
        "        duration = self.get_audio_duration(dst)\n",
        "        if duration > 7200:\n",
        "            print(f\"⚠ Warning: Audio is {duration/60:.1f} minutes.\")\n",
        "\n",
        "        return self.transcribe_audio(dst, doc_id)\n",
        "\n",
        "    def process_parquet_file(self, parquet_path, doc_id):\n",
        "        \"\"\"Process existing parquet transcript file\"\"\"\n",
        "        print(f\"\\n=== Processing Parquet Transcript ===\")\n",
        "        try:\n",
        "            df = pd.read_parquet(parquet_path)\n",
        "\n",
        "            if \"text\" not in df.columns:\n",
        "                raise ValueError(\"Parquet file must contain a 'text' column\")\n",
        "\n",
        "            standardized_rows = []\n",
        "            for idx, row in df.iterrows():\n",
        "                standardized_row = {\n",
        "                    \"doc_id\": row.get(\"doc_id\", row.get(\"video_id\", doc_id)),\n",
        "                    \"segment_idx\": row.get(\"segment_idx\", idx),\n",
        "                    \"start_ts\": float(row.get(\"start_ts\", 0.0)),\n",
        "                    \"end_ts\": float(row.get(\"end_ts\", 0.0)),\n",
        "                    \"text\": str(row[\"text\"]).strip()\n",
        "                }\n",
        "                standardized_rows.append(standardized_row)\n",
        "\n",
        "            std_df = pd.DataFrame(standardized_rows)\n",
        "            out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "            std_df.to_parquet(out_path, index=False)\n",
        "\n",
        "            print(f\"✓ Parquet processed: {out_path} ({len(std_df)} segments)\")\n",
        "            return out_path\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing parquet file: {str(e)}\")\n",
        "\n",
        "    def process_transcript_file(self, transcript_path, doc_id):\n",
        "        \"\"\"Process existing transcript files (txt, srt, vtt, json)\"\"\"\n",
        "        print(f\"\\n=== Processing Transcript File ===\")\n",
        "        ext = pathlib.Path(transcript_path).suffix.lower()\n",
        "\n",
        "        if ext == \".txt\":\n",
        "            with open(transcript_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                text = f.read().strip()\n",
        "            rows = [{\"segment_idx\": 0, \"start_ts\": 0.0, \"end_ts\": 0.0, \"text\": text}]\n",
        "\n",
        "        elif ext == \".srt\":\n",
        "            try:\n",
        "                subs = pysrt.open(transcript_path, encoding='utf-8')\n",
        "                rows = [{\n",
        "                    \"segment_idx\": i,\n",
        "                    \"start_ts\": s.start.ordinal/1000.0,\n",
        "                    \"end_ts\": s.end.ordinal/1000.0,\n",
        "                    \"text\": s.text.replace('\\n', ' ').strip()\n",
        "                } for i, s in enumerate(subs)]\n",
        "            except NameError:\n",
        "                raise ValueError(\"pysrt not installed. Cannot process SRT files.\")\n",
        "\n",
        "        elif ext == \".vtt\":\n",
        "            try:\n",
        "                def hms_to_s(hms):\n",
        "                    parts = hms.split(':')\n",
        "                    if len(parts) == 3:\n",
        "                        h, m, s = parts\n",
        "                        return int(h)*3600 + int(m)*60 + float(s)\n",
        "                    return 0.0\n",
        "\n",
        "                rows = [{\n",
        "                    \"segment_idx\": i,\n",
        "                    \"start_ts\": hms_to_s(cap.start),\n",
        "                    \"end_ts\": hms_to_s(cap.end),\n",
        "                    \"text\": cap.text.replace('\\n', ' ').strip()\n",
        "                } for i, cap in enumerate(webvtt.read(transcript_path))]\n",
        "            except NameError:\n",
        "                raise ValueError(\"webvtt-py not installed. Cannot process VTT files.\")\n",
        "\n",
        "        elif ext == \".json\":\n",
        "            with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "                obj = json.load(f)\n",
        "            segs = obj.get(\"segments\", [])\n",
        "            rows = [{\n",
        "                \"segment_idx\": i,\n",
        "                \"start_ts\": float(s.get(\"start\", 0.0)),\n",
        "                \"end_ts\": float(s.get(\"end\", 0.0)),\n",
        "                \"text\": str(s.get(\"text\", \"\")).strip()\n",
        "            } for i, s in enumerate(segs)]\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported transcript format: {ext}\")\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.insert(0, \"doc_id\", doc_id)\n",
        "        out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "        df.to_parquet(out_path, index=False)\n",
        "        print(f\"✓ Transcript saved: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    def process_pdf(self, pdf_path, doc_id):\n",
        "        \"\"\"Process PDF file\"\"\"\n",
        "        print(f\"\\n=== Processing PDF ===\")\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        docs = loader.load()\n",
        "        text = \" \".join([doc.page_content for doc in docs])\n",
        "\n",
        "        rows = [{\"segment_idx\": 0, \"start_ts\": 0.0, \"end_ts\": 0.0, \"text\": text}]\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.insert(0, \"doc_id\", doc_id)\n",
        "        out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "        df.to_parquet(out_path, index=False)\n",
        "        print(f\"✓ PDF processed: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    def route_file(self, file_path):\n",
        "        \"\"\"Main routing function for any file type\"\"\"\n",
        "        ext = pathlib.Path(file_path).suffix.lower()\n",
        "        doc_id = self.get_file_stem(file_path)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing file: {os.path.basename(file_path)}\")\n",
        "        print(f\"File type: {ext}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        if ext in VIDEO_EXT:\n",
        "            return self.process_video(file_path, doc_id)\n",
        "        elif ext in AUDIO_EXT:\n",
        "            return self.process_audio(file_path, doc_id)\n",
        "        elif ext == \".pdf\":\n",
        "            return self.process_pdf(file_path, doc_id)\n",
        "        elif ext == \".parquet\":\n",
        "            return self.process_parquet_file(file_path, doc_id)\n",
        "        elif ext in TRANSCRIPT_EXT:\n",
        "            return self.process_transcript_file(file_path, doc_id)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {ext}\")"
      ],
      "metadata": {
        "id": "txr9Z42kEYdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# TEXT CHUNKER CLASS\n",
        "# ========================================\n",
        "class TextChunker:\n",
        "    \"\"\"Smart text chunking with sentence awareness and timestamps\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_whitespace(text):\n",
        "        import re\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def basic_cleanup(text):\n",
        "        text = text.replace(\"'\", \"'\").replace(\"\"\", \"\\\"\").replace(\"\"\", \"\\\"\")\n",
        "        return TextChunker.normalize_whitespace(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def sentence_time_expand(seg_text, seg_start, seg_end):\n",
        "        \"\"\"Split segment into sentences with proportional timestamps\"\"\"\n",
        "        txt = TextChunker.basic_cleanup(seg_text)\n",
        "        sents = [s for s in sent_tokenize(txt) if s.strip()]\n",
        "\n",
        "        if not sents:\n",
        "            return []\n",
        "\n",
        "        total_chars = sum(len(s) for s in sents)\n",
        "        if total_chars == 0:\n",
        "            return []\n",
        "\n",
        "        dur = max(0.0, float(seg_end) - float(seg_start))\n",
        "        out = []\n",
        "        cur = float(seg_start)\n",
        "\n",
        "        for s in sents:\n",
        "            frac = len(s) / total_chars\n",
        "            sdur = frac * dur\n",
        "            out.append({\"text\": s, \"start_ts\": cur, \"end_ts\": cur + sdur})\n",
        "            cur += sdur\n",
        "\n",
        "        if out:\n",
        "            out[-1][\"end_ts\"] = float(seg_end)\n",
        "\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def build_sentence_table(transcript_parquet_path):\n",
        "        \"\"\"Convert transcript to sentence-level dataframe\"\"\"\n",
        "        df = pd.read_parquet(transcript_parquet_path)\n",
        "        rows = []\n",
        "\n",
        "        for _, r in df.iterrows():\n",
        "            exp = TextChunker.sentence_time_expand(r[\"text\"], r[\"start_ts\"], r[\"end_ts\"])\n",
        "            rows.extend(exp)\n",
        "\n",
        "        if not rows:\n",
        "            rows = [{\n",
        "                \"text\": TextChunker.basic_cleanup(\" \".join(df[\"text\"].tolist())),\n",
        "                \"start_ts\": 0.0,\n",
        "                \"end_ts\": 0.0\n",
        "            }]\n",
        "\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_chunks_from_sentences(sents_df, max_chars=1800, overlap_chars=200):\n",
        "        \"\"\"Create overlapping chunks respecting sentence boundaries\"\"\"\n",
        "        chunks = []\n",
        "        buf_text = \"\"\n",
        "        buf_starts = []\n",
        "        buf_ends = []\n",
        "\n",
        "        def flush_buffer():\n",
        "            if not buf_text.strip():\n",
        "                return\n",
        "            chunks.append({\n",
        "                \"text\": buf_text.strip(),\n",
        "                \"start_ts\": min(buf_starts) if buf_starts else 0.0,\n",
        "                \"end_ts\": max(buf_ends) if buf_ends else 0.0\n",
        "            })\n",
        "\n",
        "        for _, row in sents_df.iterrows():\n",
        "            s = str(row[\"text\"]).strip()\n",
        "            st, et = float(row[\"start_ts\"]), float(row[\"end_ts\"])\n",
        "\n",
        "            if not s:\n",
        "                continue\n",
        "\n",
        "            if len(buf_text) + len(s) + 1 <= max_chars:\n",
        "                buf_text = (buf_text + \" \" + s).strip() if buf_text else s\n",
        "                buf_starts.append(st)\n",
        "                buf_ends.append(et)\n",
        "            else:\n",
        "                flush_buffer()\n",
        "                buf_text = s\n",
        "                buf_starts = [st]\n",
        "                buf_ends = [et]\n",
        "\n",
        "        flush_buffer()\n",
        "        return chunks\n",
        "\n",
        "    @staticmethod\n",
        "    def build_and_save_chunks(transcript_path, max_chars=1800, overlap_chars=200):\n",
        "        \"\"\"Main function to create and save chunks\"\"\"\n",
        "        print(f\"\\n=== Creating Chunks ===\")\n",
        "        doc_id = os.path.splitext(os.path.basename(transcript_path))[0]\n",
        "        sents_df = TextChunker.build_sentence_table(transcript_path)\n",
        "        chunks = TextChunker.make_chunks_from_sentences(sents_df, max_chars, overlap_chars)\n",
        "\n",
        "        out_rows = []\n",
        "        for i, c in enumerate(chunks):\n",
        "            out_rows.append({\n",
        "                \"doc_id\": doc_id,\n",
        "                \"chunk_idx\": i,\n",
        "                \"start_ts\": float(c[\"start_ts\"]),\n",
        "                \"end_ts\": float(c[\"end_ts\"]),\n",
        "                \"text\": c[\"text\"]\n",
        "            })\n",
        "\n",
        "        cdf = pd.DataFrame(out_rows)\n",
        "        outp = f\"{DATA}/chunks/{doc_id}_chunks.parquet\"\n",
        "        cdf.to_parquet(outp, index=False)\n",
        "        print(f\"✓ Chunks saved: {outp} ({len(cdf)} chunks)\")\n",
        "        return outp\n"
      ],
      "metadata": {
        "id": "V-2VYz8DEhzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# VECTOR STORE CLASS\n",
        "# ========================================\n",
        "class VectorStore:\n",
        "    def __init__(self, collection_name=\"quantum_notes\", model_name='sentence-transformers/all-mpnet-base-v2'):\n",
        "        self.collection_name = collection_name\n",
        "        self.embedding_function = HuggingFaceEmbeddings(model_name=model_name)\n",
        "        self.persist_directory = \"./chroma_langchain_db\"\n",
        "\n",
        "        self.vector_store = Chroma(\n",
        "            collection_name=self.collection_name,\n",
        "            embedding_function=self.embedding_function,\n",
        "            persist_directory=self.persist_directory\n",
        "        )\n",
        "\n",
        "    def add_documents(self, docs):\n",
        "        \"\"\"Add documents to vector store\"\"\"\n",
        "        print(f\"\\n=== Adding {len(docs)} documents to vector store ===\")\n",
        "        self.vector_store.add_documents(docs)\n",
        "        print(\"✓ Documents added successfully\")\n",
        "\n",
        "    def similarity_search_with_score(self, query, k=5):\n",
        "        \"\"\"Search with similarity scores\"\"\"\n",
        "        results = self.vector_store.similarity_search_with_score(query, k=k)\n",
        "        results = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "        return results\n",
        "\n",
        "    def get_all_chunks(self):\n",
        "        \"\"\"Returns a list of Document objects\"\"\"\n",
        "        raw_data = self.vector_store.get()\n",
        "        docs = raw_data[\"documents\"]\n",
        "        metadatas = raw_data.get(\"metadatas\", [{}] * len(docs))\n",
        "\n",
        "        doc_objects = [Document(page_content=doc, metadata=meta) for doc, meta in zip(docs, metadatas)]\n",
        "        return doc_objects\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Clear the vector store\"\"\"\n",
        "        if os.path.exists(self.persist_directory):\n",
        "            shutil.rmtree(self.persist_directory)\n",
        "            print(f\"✓ Cleared vector store at {self.persist_directory}\")"
      ],
      "metadata": {
        "id": "o0s4FS13Em9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# DOCUMENT SUMMARIZER CLASS\n",
        "# ========================================\n",
        "class DocumentSummarizer:\n",
        "    def __init__(self, model_name=\"llama-3.1-8b-instant\", use_groq=True):\n",
        "        \"\"\"\n",
        "        Initialize DocumentSummarizer\n",
        "\n",
        "        Args:\n",
        "            model_name: Model name to use\n",
        "            use_groq: If True, use Groq, else use OpenAI\n",
        "        \"\"\"\n",
        "        if use_groq:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "            self.llm = ChatGroq(model_name=model_name, verbose=False)\n",
        "        else:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_TOKEN\")\n",
        "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
        "\n",
        "    def summarize_all(self, chunks):\n",
        "        \"\"\"Summarize all chunks\"\"\"\n",
        "        print(\"\\n=== Summarizing All Chunks ===\")\n",
        "        chain = load_summarize_chain(self.llm, chain_type=\"map_reduce\")\n",
        "        summary = chain.invoke(chunks)\n",
        "        return summary\n",
        "\n",
        "    def summarize_query(self, vector_store, query, k=3):\n",
        "        \"\"\"Summarize based on query\"\"\"\n",
        "        print(f\"\\n=== Generating Summary for Query: '{query}' ===\")\n",
        "        results = vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"Based on the following context, provide a meaningful and insightful summary focusing on: {query}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "DO NOT make up stuff. If the text is empty or does not contain information related to the query, say 'Information not found in documents related to the query'\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        summary = self.llm.invoke(prompt.format(query=query, context=context))\n",
        "\n",
        "        return summary, relevant_docs\n",
        "\n",
        "    def summarize_notes(self, notes):\n",
        "        \"\"\"Summarize user-provided notes\"\"\"\n",
        "        print(\"\\n=== Summarizing Notes ===\")\n",
        "        prompt_template = \"\"\"Based on the given notes: {notes}, provide a meaningful and insightful summary.\n",
        "DO NOT make up stuff. If the notes are empty, say 'Notes not found!'\n",
        "Summary:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"notes\"])\n",
        "        summary = self.llm.invoke(prompt.format(notes=notes))\n",
        "        return summary"
      ],
      "metadata": {
        "id": "gXwRWQXTEr5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FLASHCARDS CLASS\n",
        "# ========================================\n",
        "class FlashCards:\n",
        "    def __init__(self, model_name=\"llama-3.1-8b-instant\", use_groq=True):\n",
        "        if use_groq:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API\")\n",
        "            self.llm = ChatGroq(model_name=model_name, verbose=False)\n",
        "        else:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_TOKEN\")\n",
        "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
        "\n",
        "    def create_flashcards_on_topic(self, vector_store, query, k=3):\n",
        "        \"\"\"Create flashcards on specific topic\"\"\"\n",
        "        print(f\"\\n=== Creating Flashcards for: '{query}' ===\")\n",
        "        results = vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert in creating flashcards based on the provided information.\n",
        "\n",
        "Based on the following context, create up to 8 flashcards focusing on the topic: {query}\n",
        "\n",
        "If the concept is complex, break it down into a core definition, formula, or key takeaway.\n",
        "\n",
        "Each flashcard should have:\n",
        "1. A question or term on one side\n",
        "2. A short (2 to 3 lines), memorable answer that captures the key point(s) on the other side\n",
        "3. Simple and erudite language that is easy to understand and memorize\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Format your response as:\n",
        "Front: [Question]\n",
        "Back: [Answer]\n",
        "\n",
        "Flashcards:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        formatted_prompt = prompt.format(query=query, context=context)\n",
        "        cards = self.llm.invoke(formatted_prompt)\n",
        "\n",
        "        return cards, relevant_docs\n",
        "\n",
        "    def create_flashcards_based_notes(self, notes):\n",
        "        \"\"\"Create flashcards from notes\"\"\"\n",
        "        print(\"\\n=== Creating Flashcards from Notes ===\")\n",
        "        prompt_template = \"\"\"You are an expert in creating flashcards based on the provided information.\n",
        "\n",
        "Based on the following notes, create up to 8 flashcards.\n",
        "notes: {notes}\n",
        "\n",
        "If the concept is complex, break it down into a core definition, formula, or key takeaway.\n",
        "\n",
        "Each flashcard should have:\n",
        "1. A question or term on one side\n",
        "2. A short (2 to 3 lines), memorable answer that captures the key point(s) on the other side\n",
        "3. Simple and erudite language that is easy to understand and memorize\n",
        "\n",
        "Format your response as:\n",
        "Front: [Question]\n",
        "Back: [Answer]\n",
        "\n",
        "Flashcards:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"notes\"]\n",
        "        )\n",
        "        cards = self.llm.invoke(prompt.format(notes=notes))\n",
        "        return cards"
      ],
      "metadata": {
        "id": "EB9XKK1tExRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# QUIZ GENERATOR CLASS\n",
        "# ========================================\n",
        "class QuizGenerator:\n",
        "    def __init__(self, model_name=\"llama-3.1-8b-instant\", use_groq=True):\n",
        "        if use_groq:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "            self.llm = ChatGroq(model_name=model_name, verbose=False)\n",
        "        else:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_TOKEN\")\n",
        "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "\n",
        "    def generate_quiz_all(self, chunks, num_questions=10):\n",
        "        \"\"\"Generate quiz from all chunks\"\"\"\n",
        "        print(f\"\\n=== Generating Quiz ({num_questions} questions) ===\")\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in chunks[:15]])\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert quiz creator. Based on the following content, create a quiz with {num_questions} multiple-choice questions.\n",
        "\n",
        "Content:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "1. Create {num_questions} questions that test key concepts and understanding\n",
        "2. Each question should have 4 options (A, B, C, D)\n",
        "3. Mark the correct answer\n",
        "4. Cover different topics/concepts from the content\n",
        "5. Mix difficulty levels (easy, medium, hard)\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Question 1: [Question text]\n",
        "A) [Option A]\n",
        "B) [Option B]\n",
        "C) [Option C]\n",
        "D) [Option D]\n",
        "Correct Answer: [A/B/C/D]\n",
        "Explanation: [Brief explanation of why this is correct]\n",
        "\n",
        "[Continue for all {num_questions} questions]\n",
        "\n",
        "Quiz:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"num_questions\", \"context\"]\n",
        "        )\n",
        "\n",
        "        quiz = self.llm.invoke(prompt.format(num_questions=num_questions, context=context))\n",
        "        print(\"✓ Quiz generation complete!\")\n",
        "        return quiz\n",
        "\n",
        "    def generate_quiz_on_topic(self, vector_store, query, num_questions=10, k=5):\n",
        "        \"\"\"Generate quiz on specific topic\"\"\"\n",
        "        print(f\"\\n=== Generating Quiz on Topic: '{query}' ({num_questions} questions) ===\")\n",
        "        results = vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert quiz creator. Based on the following context, create a quiz with {num_questions} multiple-choice questions focusing on: {query}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "1. Create {num_questions} questions specifically about: {query}\n",
        "2. Each question should have 4 options (A, B, C, D)\n",
        "3. Mark the correct answer\n",
        "4. Questions should test understanding of the topic\n",
        "5. Mix difficulty levels (easy, medium, hard)\n",
        "\n",
        "DO NOT make up information. If the context doesn't contain enough information about the query, create fewer questions and mention: \"Limited information available for full quiz on this topic.\"\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Question 1: [Question text]\n",
        "A) [Option A]\n",
        "B) [Option B]\n",
        "C) [Option C]\n",
        "D) [Option D]\n",
        "Correct Answer: [A/B/C/D]\n",
        "Explanation: [Brief explanation]\n",
        "\n",
        "[Continue for all questions]\n",
        "\n",
        "Quiz:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"num_questions\", \"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        quiz = self.llm.invoke(\n",
        "            prompt.format(num_questions=num_questions, query=query, context=context)\n",
        "        )\n",
        "\n",
        "        print(\"✓ Quiz generation complete!\")\n",
        "        return quiz, relevant_docs\n",
        "\n",
        "    def generate_quiz_from_notes(self, notes, num_questions=10):\n",
        "        \"\"\"Generate quiz from notes\"\"\"\n",
        "        print(f\"\\n=== Generating Quiz from Notes ({num_questions} questions) ===\")\n",
        "        prompt_template = \"\"\"You are an expert quiz creator. Based on the given notes, create a quiz with {num_questions} multiple-choice questions.\n",
        "\n",
        "Notes:\n",
        "{notes}\n",
        "\n",
        "Instructions:\n",
        "1. Create {num_questions} questions that test understanding of the notes\n",
        "2. Each question should have 4 options (A, B, C, D)\n",
        "3. Mark the correct answer\n",
        "4. Cover key concepts from the notes\n",
        "5. Mix difficulty levels (easy, medium, hard)\n",
        "\n",
        "DO NOT make up stuff. If the notes are empty or too short, say 'Notes insufficient for quiz generation!'\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Question 1: [Question text]\n",
        "A) [Option A]\n",
        "B) [Option B]\n",
        "C) [Option C]\n",
        "D) [Option D]\n",
        "Correct Answer: [A/B/C/D]\n",
        "Explanation: [Brief explanation]\n",
        "\n",
        "[Continue for all {num_questions} questions]\n",
        "\n",
        "Quiz:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"num_questions\", \"notes\"]\n",
        "        )\n",
        "\n",
        "        quiz = self.llm.invoke(prompt.format(num_questions=num_questions, notes=notes))\n",
        "        print(\"✓ Quiz generation complete!\")\n",
        "        return quiz"
      ],
      "metadata": {
        "id": "KeMy-Sn8E2cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# MAIN PIPELINE CLASS\n",
        "# ========================================\n",
        "class QuantumNotesPipeline:\n",
        "    \"\"\"\n",
        "    Main pipeline for QuantumNotes with multimodal support\n",
        "\n",
        "    Supports:\n",
        "    - Videos (mp4, mkv, mov, avi)\n",
        "    - Audio (wav, mp3, m4a, flac, aac, ogg)\n",
        "    - PDFs\n",
        "    - Text files\n",
        "    - Transcripts (txt, srt, vtt, json, parquet)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_groq=True):\n",
        "        \"\"\"\n",
        "        Initialize pipeline\n",
        "\n",
        "        Args:\n",
        "            use_groq: If True, use Groq for LLM, else use OpenAI\n",
        "        \"\"\"\n",
        "        self.file_processor = FileProcessor()\n",
        "        self.use_groq = use_groq\n",
        "        self.vector_store = None\n",
        "        self.current_doc_id = None\n",
        "\n",
        "    def process_file(self, file_path):\n",
        "        \"\"\"\n",
        "        Process any supported file type\n",
        "\n",
        "        Args:\n",
        "            file_path: Path to the file\n",
        "\n",
        "        Returns:\n",
        "            VectorStore instance ready for querying\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"QUANTUMNOTES MULTIMODAL PIPELINE\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Step 1: Process file (video/audio/pdf/transcript)\n",
        "        transcript_path = self.file_processor.route_file(file_path)\n",
        "        self.current_doc_id = self.file_processor.get_file_stem(file_path)\n",
        "\n",
        "        # Step 2: Create chunks\n",
        "        chunks_path = TextChunker.build_and_save_chunks(\n",
        "            transcript_path,\n",
        "            max_chars=CHUNK_SIZE,\n",
        "            overlap_chars=CHUNK_OVERLAP\n",
        "        )\n",
        "\n",
        "        # Step 3: Load chunks as documents\n",
        "        df = pd.read_parquet(chunks_path)\n",
        "        documents = [\n",
        "            Document(\n",
        "                page_content=row[\"text\"],\n",
        "                metadata={\n",
        "                    \"doc_id\": row[\"doc_id\"],\n",
        "                    \"chunk_idx\": row[\"chunk_idx\"],\n",
        "                    \"start_ts\": row[\"start_ts\"],\n",
        "                    \"end_ts\": row[\"end_ts\"]\n",
        "                }\n",
        "            ) for _, row in df.iterrows()\n",
        "        ]\n",
        "\n",
        "        # Step 4: Create vector store\n",
        "        print(f\"\\n=== Building Vector Store ===\")\n",
        "        self.vector_store = VectorStore(collection_name=f\"quantum_{self.current_doc_id}\")\n",
        "        self.vector_store.add_documents(documents)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"✓ File processing complete!\")\n",
        "        print(f\"✓ Document ID: {self.current_doc_id}\")\n",
        "        print(f\"✓ Total chunks: {len(documents)}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        return self.vector_store\n",
        "\n",
        "    def summarize(self, query, k=3):\n",
        "        \"\"\"Generate summary based on query\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        ds = DocumentSummarizer(use_groq=self.use_groq)\n",
        "        summary, relevant_docs = ds.summarize_query(self.vector_store, query, k=k)\n",
        "        return summary\n",
        "\n",
        "    def summarize_all(self):\n",
        "        \"\"\"Summarize entire document\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        ds = DocumentSummarizer(use_groq=self.use_groq)\n",
        "        all_chunks = self.vector_store.get_all_chunks()\n",
        "        summary = ds.summarize_all(all_chunks)\n",
        "        return summary\n",
        "\n",
        "    def make_notes(self, query, k=3):\n",
        "        \"\"\"Create structured notes\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        # Use summarizer to generate notes-style content\n",
        "        ds = DocumentSummarizer(use_groq=self.use_groq)\n",
        "        results = self.vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert in analyzing documents and creating meaningful notes.\n",
        "\n",
        "Based on the following text:\n",
        "{context}\n",
        "\n",
        "Create structured notes focusing on the query: {query}\n",
        "\n",
        "These notes should have:\n",
        "1. Key Points: [main ideas]\n",
        "2. Important Details: [supporting information]\n",
        "3. Actionable Insights: [what can be done]\n",
        "4. Additional Information: [any other relevant details from the text]\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        notes = ds.llm.invoke(prompt.format(query=query, context=context))\n",
        "\n",
        "        return notes\n",
        "\n",
        "    def create_flashcards(self, query, k=3):\n",
        "        \"\"\"Generate flashcards on topic\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        fc = FlashCards(use_groq=self.use_groq)\n",
        "        cards, relevant_docs = fc.create_flashcards_on_topic(self.vector_store, query, k=k)\n",
        "        return cards\n",
        "\n",
        "    def generate_quiz(self, query=None, num_questions=10, k=5):\n",
        "        \"\"\"Generate quiz\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        qg = QuizGenerator(use_groq=self.use_groq)\n",
        "\n",
        "        if query:\n",
        "            quiz, relevant_docs = qg.generate_quiz_on_topic(\n",
        "                self.vector_store,\n",
        "                query,\n",
        "                num_questions=num_questions,\n",
        "                k=k\n",
        "            )\n",
        "        else:\n",
        "            all_chunks = self.vector_store.get_all_chunks()\n",
        "            quiz = qg.generate_quiz_all(all_chunks, num_questions=num_questions)\n",
        "\n",
        "        return quiz\n",
        "\n",
        "    def search(self, query, k=5):\n",
        "        \"\"\"Search for relevant chunks\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        results = self.vector_store.similarity_search_with_score(query, k=k)\n",
        "        return results"
      ],
      "metadata": {
        "id": "Pn4HABqjFFDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "\n",
        "file_path = \"/content/MCAKCA032-PRINCIPALES OF SOFT COMPUTING-SN SIVNANDAM AND DEEPA SN (1).pdf\"\n",
        "pipeline.process_file(file_path)\n",
        "\n",
        "summary = pipeline.summarize(\"What is Linear Vector Quantization?\")\n",
        "print(summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3z7igKCFL0C",
        "outputId": "2d54c985-926c-4d44-bb50-b3b3a7185db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "QUANTUMNOTES MULTIMODAL PIPELINE\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Processing file: MCAKCA032-PRINCIPALES OF SOFT COMPUTING-SN SIVNANDAM AND DEEPA SN (1).pdf\n",
            "File type: .pdf\n",
            "============================================================\n",
            "\n",
            "=== Processing PDF ===\n",
            "✓ PDF processed: ./data/transcripts/MCAKCA032-PRINCIPALES_OF_SOFT_COMPUTING-SN_SIVNANDAM_AND_DEEPA_SN__1.parquet\n",
            "\n",
            "=== Creating Chunks ===\n",
            "✓ Chunks saved: ./data/chunks/MCAKCA032-PRINCIPALES_OF_SOFT_COMPUTING-SN_SIVNANDAM_AND_DEEPA_SN__1_chunks.parquet (786 chunks)\n",
            "\n",
            "=== Building Vector Store ===\n",
            "\n",
            "=== Adding 786 documents to vector store ===\n",
            "✓ Documents added successfully\n",
            "\n",
            "============================================================\n",
            "✓ File processing complete!\n",
            "✓ Document ID: MCAKCA032-PRINCIPALES_OF_SOFT_COMPUTING-SN_SIVNANDAM_AND_DEEPA_SN__1\n",
            "✓ Total chunks: 786\n",
            "============================================================\n",
            "\n",
            "\n",
            "=== Generating Summary for Query: 'What is Linear Vector Quantization?' ===\n",
            "Information not found in documents related to the query\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "file_path = \"/content/ana-bell-v1.mp3\"\n",
        "pipeline.process_file(file_path)\n",
        "summary = pipeline.summarize(\"Key concepts\")\n",
        "print(summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgYg3TBMFmAW",
        "outputId": "3d753fe8-9b30-434a-d815-e271fa2a61e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "QUANTUMNOTES MULTIMODAL PIPELINE\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Processing file: ana-bell-v1.mp3\n",
            "File type: .mp3\n",
            "============================================================\n",
            "\n",
            "=== Processing Audio ===\n",
            "Converting .mp3 to WAV...\n",
            "✓ Audio ready: ./data/audio/ana-bell-v1.wav\n",
            "Initializing Whisper model...\n",
            "Transcribing audio: ./data/audio/ana-bell-v1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "cards = pipeline.create_flashcards(\"Important terms\")\n",
        "print(cards.content)"
      ],
      "metadata": {
        "id": "V9bCHt3hFrhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "quiz = pipeline.generate_quiz(\"Core concepts\", num_questions=5)\n",
        "print(quiz.content)"
      ],
      "metadata": {
        "id": "ZLYfeOAtFxMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "results = pipeline.search(\"specific topic\", k=3)\n",
        "for doc, score in results:\n",
        "      print(f\"Score: {score}\")\n",
        "      print(doc.page_content)\n",
        "      print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "1pEomXUxF7Fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}