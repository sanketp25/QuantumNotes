{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZRaZ3GqDrxN",
        "outputId": "cbdb4984-d43e-4c4b-d9a6-c47c22f5552b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Collecting faster-whisper (from -r requirements.txt (line 7))\n",
            "  Downloading faster_whisper-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ffmpeg-python (from -r requirements.txt (line 8))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.9.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (5.1.1)\n",
            "Collecting pysrt (from -r requirements.txt (line 15))\n",
            "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting webvtt-py (from -r requirements.txt (line 16))\n",
            "  Downloading webvtt_py-0.5.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (0.3.27)\n",
            "Collecting langchain-community (from -r requirements.txt (line 20))\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (0.3.11)\n",
            "Collecting langchain-experimental (from -r requirements.txt (line 23))\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-groq (from -r requirements.txt (line 26))\n",
            "  Downloading langchain_groq-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-openai (from -r requirements.txt (line 27))\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-huggingface (from -r requirements.txt (line 28))\n",
            "  Downloading langchain_huggingface-1.0.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langchain-chroma (from -r requirements.txt (line 29))\n",
            "  Downloading langchain_chroma-1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langgraph (from -r requirements.txt (line 32))\n",
            "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting chromadb (from -r requirements.txt (line 35))\n",
            "  Downloading chromadb-1.2.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting pypdf (from -r requirements.txt (line 38))\n",
            "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting python-docx (from -r requirements.txt (line 39))\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pymupdf (from -r requirements.txt (line 40))\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 44)) (4.57.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper->-r requirements.txt (line 7))\n",
            "  Downloading ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper->-r requirements.txt (line 7)) (0.35.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper->-r requirements.txt (line 7)) (0.22.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper->-r requirements.txt (line 7))\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting av>=11 (from faster-whisper->-r requirements.txt (line 7))\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 11)) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 11)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 11)) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 12)) (4.15.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from pysrt->-r requirements.txt (line 15)) (5.2.0)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (0.4.37)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 19)) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community (from -r requirements.txt (line 20))\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests<3,>=2 (from langchain->-r requirements.txt (line 19))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community->-r requirements.txt (line 20))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 20)) (0.4.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 21)) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core->-r requirements.txt (line 21)) (25.0)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq->-r requirements.txt (line 26))\n",
            "  Downloading groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-groq (from -r requirements.txt (line 26))\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai (from -r requirements.txt (line 27))\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r requirements.txt (line 27)) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r requirements.txt (line 27)) (0.12.0)\n",
            "INFO: pip is looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-huggingface (from -r requirements.txt (line 28))\n",
            "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "INFO: pip is looking at multiple versions of langchain-chroma to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-chroma (from -r requirements.txt (line 29))\n",
            "  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph->-r requirements.txt (line 32))\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph->-r requirements.txt (line 32))\n",
            "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph->-r requirements.txt (line 32))\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph->-r requirements.txt (line 32)) (3.6.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35)) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.37.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 35)) (4.25.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx->-r requirements.txt (line 39)) (5.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 43)) (3.4.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 44)) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 20)) (1.22.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 35)) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 20))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 20))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq->-r requirements.txt (line 26)) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq->-r requirements.txt (line 26)) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq->-r requirements.txt (line 26)) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 35)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper->-r requirements.txt (line 7)) (1.1.10)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r requirements.txt (line 21)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 35)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 35)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 35)) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph->-r requirements.txt (line 32))\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 19)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 19)) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7)) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai->-r requirements.txt (line 27)) (0.11.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 35)) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 35)) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb->-r requirements.txt (line 35))\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 19)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 19)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 19)) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->-r requirements.txt (line 20)) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 19)) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 35)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 35)) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 19)) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 43)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 35)) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35))\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 35)) (15.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 43)) (3.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 12)) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 35)) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 35)) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 20))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 7))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 35)) (0.6.1)\n",
            "Downloading faster_whisper-1.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading webvtt_py-0.5.1-py3-none-any.whl (19 kB)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n",
            "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.2.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.7/20.7 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.33.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pysrt, pypika\n",
            "  Building wheel for pysrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13443 sha256=665f6ca463aab36862bd6934784ed42f8d1a31f872ac02fc4e5a7e4cabe28990\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/36/54/2aa8dc961885dfa7b0ebd45a57505f25039d79b4ea0fd9f29d\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=fd99921de6a6b289f6b11b2a6f08e79f4f5b2e188de3811bd5b5630ac16e8cd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pysrt pypika\n",
            "Installing collected packages: pypika, durationpy, webvtt-py, uvloop, urllib3, python-docx, pysrt, pypdf, pymupdf, pybase64, ormsgpack, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httptools, ffmpeg-python, ctranslate2, bcrypt, backoff, av, watchfiles, typing-inspect, requests, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, onnxruntime, langgraph-sdk, groq, dataclasses-json, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, faster-whisper, langgraph-checkpoint, langchain-openai, langchain-huggingface, langchain-groq, chromadb, langgraph-prebuilt, langchain-chroma, langgraph, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed av-16.0.1 backoff-2.2.1 bcrypt-5.0.0 chromadb-1.2.1 coloredlogs-15.0.1 ctranslate2-4.6.0 dataclasses-json-0.6.7 durationpy-0.10 faster-whisper-1.2.0 ffmpeg-python-0.2.0 groq-0.33.0 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-chroma-0.2.6 langchain-community-0.3.31 langchain-experimental-0.3.4 langchain-groq-0.3.8 langchain-huggingface-0.3.1 langchain-openai-0.3.35 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 ormsgpack-1.11.0 posthog-5.4.0 pybase64-1.4.2 pymupdf-1.26.5 pypdf-6.1.3 pypika-0.48.9 pysrt-1.1.2 python-docx-1.2.0 requests-2.32.5 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1 webvtt-py-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "OtUlPaDZERfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# IMPORTS\n",
        "# ========================================\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import pathlib\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, TypedDict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Whisper and audio processing\n",
        "from faster_whisper import WhisperModel\n",
        "import ffmpeg\n",
        "\n",
        "# Text processing\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.schema import Document\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "# LLM\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# For subtitle parsing\n",
        "try:\n",
        "    import pysrt\n",
        "except ImportError:\n",
        "    print(\"pysrt not installed. SRT support will be limited.\")\n",
        "try:\n",
        "    import webvtt\n",
        "except ImportError:\n",
        "    print(\"webvtt-py not installed. VTT support will be limited.\")\n",
        "\n",
        "# Google Colab userdata (comment out if not using Colab)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Not running in Colab. Make sure to set environment variables manually.\")"
      ],
      "metadata": {
        "id": "6A4bElbjEL1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f4896d-97eb-4d65-834b-c507c8cf4a73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CONFIGURATION\n",
        "# ========================================\n",
        "WHISPER_MODEL = \"medium\"\n",
        "VIDEO_EXT = {\".mp4\", \".mkv\", \".mov\", \".avi\"}\n",
        "AUDIO_EXT = {\".wav\", \".mp3\", \".m4a\", \".flac\", \".aac\", \".ogg\"}\n",
        "TRANSCRIPT_EXT = {\".txt\", \".srt\", \".vtt\", \".json\"}\n",
        "CHUNK_SIZE = 1800\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "# Directory setup\n",
        "BASE = \".\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "os.makedirs(f\"{DATA}/audio\", exist_ok=True)\n",
        "os.makedirs(f\"{DATA}/transcripts\", exist_ok=True)\n",
        "os.makedirs(f\"{DATA}/chunks\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "RVuvuKuHEUQ2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Processor"
      ],
      "metadata": {
        "id": "YAE6a2ZNEfjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FILE PROCESSOR CLASS\n",
        "# ========================================\n",
        "class FileProcessor:\n",
        "    \"\"\"Handles file upload, format detection, and routing\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.whisper_model = None\n",
        "\n",
        "    def initialize_whisper(self):\n",
        "        \"\"\"Initialize Whisper model once\"\"\"\n",
        "        if self.whisper_model is None:\n",
        "            print(\"Initializing Whisper model...\")\n",
        "            self.whisper_model = WhisperModel(\n",
        "                WHISPER_MODEL,\n",
        "                device=\"cuda\",\n",
        "                compute_type=\"float16\"\n",
        "            )\n",
        "            gc.collect()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_file_stem(fname):\n",
        "        stem = pathlib.Path(fname).stem\n",
        "        # Sanitize the stem for use in collection names\n",
        "        import re\n",
        "        sanitized_stem = re.sub(r'[^a-zA-Z0-9._-]', '_', stem)\n",
        "        sanitized_stem = sanitized_stem.strip('_-.')  # removes leading/trailing invalid chars\n",
        "        if len(sanitized_stem) < 3:\n",
        "         sanitized_stem = f\"doc_{sanitized_stem}\"\n",
        "        return sanitized_stem\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_audio_duration(audio_path):\n",
        "        \"\"\"Get audio duration in seconds\"\"\"\n",
        "        try:\n",
        "            probe = ffmpeg.probe(audio_path)\n",
        "            return float(probe['format']['duration'])\n",
        "        except ffmpeg.Error as e:\n",
        "            print(f\"Error getting duration: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def extract_audio_from_video(self, video_path, out_audio_path, sr=16000):\n",
        "        \"\"\"Convert video to audio\"\"\"\n",
        "        if not os.path.exists(out_audio_path):\n",
        "            print(f\"Extracting audio from video: {video_path}\")\n",
        "            (\n",
        "                ffmpeg\n",
        "                .input(video_path)\n",
        "                .output(out_audio_path, ac=1, ar=sr, format='wav', loglevel=\"error\")\n",
        "                .overwrite_output()\n",
        "                .run()\n",
        "            )\n",
        "            print(f\"✓ Audio extracted: {out_audio_path}\")\n",
        "        return out_audio_path\n",
        "\n",
        "    def transcribe_audio(self, audio_path, doc_id):\n",
        "        \"\"\"Transcribe audio using Whisper\"\"\"\n",
        "        self.initialize_whisper()\n",
        "\n",
        "        print(f\"Transcribing audio: {audio_path}\")\n",
        "        segments, info = self.whisper_model.transcribe(\n",
        "            audio_path,\n",
        "            beam_size=5,\n",
        "            vad_filter=True,\n",
        "            word_timestamps=False\n",
        "        )\n",
        "\n",
        "        rows = []\n",
        "        for i, seg in enumerate(segments):\n",
        "            rows.append({\n",
        "                \"doc_id\": doc_id,\n",
        "                \"segment_idx\": i,\n",
        "                \"start_ts\": float(seg.start),\n",
        "                \"end_ts\": float(seg.end),\n",
        "                \"text\": seg.text.strip()\n",
        "            })\n",
        "\n",
        "        out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "        pd.DataFrame(rows).to_parquet(out_path, index=False)\n",
        "        print(f\"✓ Transcript saved: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    def process_video(self, video_path, doc_id):\n",
        "        \"\"\"Process video: extract audio, transcribe\"\"\"\n",
        "        print(f\"\\n=== Processing Video ===\")\n",
        "        audio_path = f\"{DATA}/audio/{doc_id}.wav\"\n",
        "        self.extract_audio_from_video(video_path, audio_path)\n",
        "\n",
        "        duration = self.get_audio_duration(audio_path)\n",
        "        if duration > 7200:  # 2 hours\n",
        "            print(f\"⚠ Warning: Audio is {duration/60:.1f} minutes. This may take a while.\")\n",
        "\n",
        "        return self.transcribe_audio(audio_path, doc_id)\n",
        "\n",
        "    def process_audio(self, audio_path, doc_id):\n",
        "        \"\"\"Process audio file directly\"\"\"\n",
        "        print(f\"\\n=== Processing Audio ===\")\n",
        "        ext = pathlib.Path(audio_path).suffix.lower()\n",
        "        dst = f\"{DATA}/audio/{doc_id}.wav\"\n",
        "\n",
        "        if ext == \".wav\":\n",
        "            shutil.copy(audio_path, dst)\n",
        "        else:\n",
        "            print(f\"Converting {ext} to WAV...\")\n",
        "            (\n",
        "                ffmpeg\n",
        "                .input(audio_path)\n",
        "                .output(dst, ac=1, ar=16000, format='wav', loglevel=\"error\")\n",
        "                .overwrite_output()\n",
        "                .run()\n",
        "            )\n",
        "\n",
        "        print(f\"✓ Audio ready: {dst}\")\n",
        "\n",
        "        duration = self.get_audio_duration(dst)\n",
        "        if duration > 7200:\n",
        "            print(f\"⚠ Warning: Audio is {duration/60:.1f} minutes.\")\n",
        "\n",
        "        return self.transcribe_audio(dst, doc_id)\n",
        "\n",
        "    def process_parquet_file(self, parquet_path, doc_id):\n",
        "        \"\"\"Process existing parquet transcript file\"\"\"\n",
        "        print(f\"\\n=== Processing Parquet Transcript ===\")\n",
        "        try:\n",
        "            df = pd.read_parquet(parquet_path)\n",
        "\n",
        "            if \"text\" not in df.columns:\n",
        "                raise ValueError(\"Parquet file must contain a 'text' column\")\n",
        "\n",
        "            standardized_rows = []\n",
        "            for idx, row in df.iterrows():\n",
        "                standardized_row = {\n",
        "                    \"doc_id\": row.get(\"doc_id\", row.get(\"video_id\", doc_id)),\n",
        "                    \"segment_idx\": row.get(\"segment_idx\", idx),\n",
        "                    \"start_ts\": float(row.get(\"start_ts\", 0.0)),\n",
        "                    \"end_ts\": float(row.get(\"end_ts\", 0.0)),\n",
        "                    \"text\": str(row[\"text\"]).strip()\n",
        "                }\n",
        "                standardized_rows.append(standardized_row)\n",
        "\n",
        "            std_df = pd.DataFrame(standardized_rows)\n",
        "            out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "            std_df.to_parquet(out_path, index=False)\n",
        "\n",
        "            print(f\"✓ Parquet processed: {out_path} ({len(std_df)} segments)\")\n",
        "            return out_path\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing parquet file: {str(e)}\")\n",
        "\n",
        "    def process_transcript_file(self, transcript_path, doc_id):\n",
        "        \"\"\"Process existing transcript files (txt, srt, vtt, json)\"\"\"\n",
        "        print(f\"\\n=== Processing Transcript File ===\")\n",
        "        ext = pathlib.Path(transcript_path).suffix.lower()\n",
        "\n",
        "        if ext == \".txt\":\n",
        "            with open(transcript_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                text = f.read().strip()\n",
        "            rows = [{\"segment_idx\": 0, \"start_ts\": 0.0, \"end_ts\": 0.0, \"text\": text}]\n",
        "\n",
        "        elif ext == \".srt\":\n",
        "            try:\n",
        "                subs = pysrt.open(transcript_path, encoding='utf-8')\n",
        "                rows = [{\n",
        "                    \"segment_idx\": i,\n",
        "                    \"start_ts\": s.start.ordinal/1000.0,\n",
        "                    \"end_ts\": s.end.ordinal/1000.0,\n",
        "                    \"text\": s.text.replace('\\n', ' ').strip()\n",
        "                } for i, s in enumerate(subs)]\n",
        "            except NameError:\n",
        "                raise ValueError(\"pysrt not installed. Cannot process SRT files.\")\n",
        "\n",
        "        elif ext == \".vtt\":\n",
        "            try:\n",
        "                def hms_to_s(hms):\n",
        "                    parts = hms.split(':')\n",
        "                    if len(parts) == 3:\n",
        "                        h, m, s = parts\n",
        "                        return int(h)*3600 + int(m)*60 + float(s)\n",
        "                    return 0.0\n",
        "\n",
        "                rows = [{\n",
        "                    \"segment_idx\": i,\n",
        "                    \"start_ts\": hms_to_s(cap.start),\n",
        "                    \"end_ts\": hms_to_s(cap.end),\n",
        "                    \"text\": cap.text.replace('\\n', ' ').strip()\n",
        "                } for i, cap in enumerate(webvtt.read(transcript_path))]\n",
        "            except NameError:\n",
        "                raise ValueError(\"webvtt-py not installed. Cannot process VTT files.\")\n",
        "\n",
        "        elif ext == \".json\":\n",
        "            with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "                obj = json.load(f)\n",
        "            segs = obj.get(\"segments\", [])\n",
        "            rows = [{\n",
        "                \"segment_idx\": i,\n",
        "                \"start_ts\": float(s.get(\"start\", 0.0)),\n",
        "                \"end_ts\": float(s.get(\"end\", 0.0)),\n",
        "                \"text\": str(s.get(\"text\", \"\")).strip()\n",
        "            } for i, s in enumerate(segs)]\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported transcript format: {ext}\")\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.insert(0, \"doc_id\", doc_id)\n",
        "        out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "        df.to_parquet(out_path, index=False)\n",
        "        print(f\"✓ Transcript saved: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    def process_pdf(self, pdf_path, doc_id):\n",
        "        \"\"\"Process PDF file\"\"\"\n",
        "        print(f\"\\n=== Processing PDF ===\")\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        docs = loader.load()\n",
        "        text = \" \".join([doc.page_content for doc in docs])\n",
        "\n",
        "        rows = [{\"segment_idx\": 0, \"start_ts\": 0.0, \"end_ts\": 0.0, \"text\": text}]\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.insert(0, \"doc_id\", doc_id)\n",
        "        out_path = f\"{DATA}/transcripts/{doc_id}.parquet\"\n",
        "        df.to_parquet(out_path, index=False)\n",
        "        print(f\"✓ PDF processed: {out_path}\")\n",
        "        return out_path\n",
        "\n",
        "    def route_file(self, file_path):\n",
        "        \"\"\"Main routing function for any file type\"\"\"\n",
        "        ext = pathlib.Path(file_path).suffix.lower()\n",
        "        doc_id = self.get_file_stem(file_path)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing file: {os.path.basename(file_path)}\")\n",
        "        print(f\"File type: {ext}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        if ext in VIDEO_EXT:\n",
        "            return self.process_video(file_path, doc_id)\n",
        "        elif ext in AUDIO_EXT:\n",
        "            return self.process_audio(file_path, doc_id)\n",
        "        elif ext == \".pdf\":\n",
        "            return self.process_pdf(file_path, doc_id)\n",
        "        elif ext == \".parquet\":\n",
        "            return self.process_parquet_file(file_path, doc_id)\n",
        "        elif ext in TRANSCRIPT_EXT:\n",
        "            return self.process_transcript_file(file_path, doc_id)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {ext}\")"
      ],
      "metadata": {
        "id": "txr9Z42kEYdp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# TEXT CHUNKER CLASS\n",
        "# ========================================\n",
        "class TextChunker:\n",
        "    \"\"\"Smart text chunking with sentence awareness and timestamps\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_whitespace(text):\n",
        "        import re\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def basic_cleanup(text):\n",
        "        text = text.replace(\"'\", \"'\").replace(\"\"\", \"\\\"\").replace(\"\"\", \"\\\"\")\n",
        "        return TextChunker.normalize_whitespace(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def sentence_time_expand(seg_text, seg_start, seg_end):\n",
        "        \"\"\"Split segment into sentences with proportional timestamps\"\"\"\n",
        "        txt = TextChunker.basic_cleanup(seg_text)\n",
        "        sents = [s for s in sent_tokenize(txt) if s.strip()]\n",
        "\n",
        "        if not sents:\n",
        "            return []\n",
        "\n",
        "        total_chars = sum(len(s) for s in sents)\n",
        "        if total_chars == 0:\n",
        "            return []\n",
        "\n",
        "        dur = max(0.0, float(seg_end) - float(seg_start))\n",
        "        out = []\n",
        "        cur = float(seg_start)\n",
        "\n",
        "        for s in sents:\n",
        "            frac = len(s) / total_chars\n",
        "            sdur = frac * dur\n",
        "            out.append({\"text\": s, \"start_ts\": cur, \"end_ts\": cur + sdur})\n",
        "            cur += sdur\n",
        "\n",
        "        if out:\n",
        "            out[-1][\"end_ts\"] = float(seg_end)\n",
        "\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def build_sentence_table(transcript_parquet_path):\n",
        "        \"\"\"Convert transcript to sentence-level dataframe\"\"\"\n",
        "        df = pd.read_parquet(transcript_parquet_path)\n",
        "        rows = []\n",
        "\n",
        "        for _, r in df.iterrows():\n",
        "            exp = TextChunker.sentence_time_expand(r[\"text\"], r[\"start_ts\"], r[\"end_ts\"])\n",
        "            rows.extend(exp)\n",
        "\n",
        "        if not rows:\n",
        "            rows = [{\n",
        "                \"text\": TextChunker.basic_cleanup(\" \".join(df[\"text\"].tolist())),\n",
        "                \"start_ts\": 0.0,\n",
        "                \"end_ts\": 0.0\n",
        "            }]\n",
        "\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_chunks_from_sentences(sents_df, max_chars=1800, overlap_chars=200):\n",
        "        \"\"\"Create overlapping chunks respecting sentence boundaries\"\"\"\n",
        "        chunks = []\n",
        "        buf_text = \"\"\n",
        "        buf_starts = []\n",
        "        buf_ends = []\n",
        "\n",
        "        def flush_buffer():\n",
        "            if not buf_text.strip():\n",
        "                return\n",
        "            chunks.append({\n",
        "                \"text\": buf_text.strip(),\n",
        "                \"start_ts\": min(buf_starts) if buf_starts else 0.0,\n",
        "                \"end_ts\": max(buf_ends) if buf_ends else 0.0\n",
        "            })\n",
        "\n",
        "        for _, row in sents_df.iterrows():\n",
        "            s = str(row[\"text\"]).strip()\n",
        "            st, et = float(row[\"start_ts\"]), float(row[\"end_ts\"])\n",
        "\n",
        "            if not s:\n",
        "                continue\n",
        "\n",
        "            if len(buf_text) + len(s) + 1 <= max_chars:\n",
        "                buf_text = (buf_text + \" \" + s).strip() if buf_text else s\n",
        "                buf_starts.append(st)\n",
        "                buf_ends.append(et)\n",
        "            else:\n",
        "                flush_buffer()\n",
        "                buf_text = s\n",
        "                buf_starts = [st]\n",
        "                buf_ends = [et]\n",
        "\n",
        "        flush_buffer()\n",
        "        return chunks\n",
        "\n",
        "    @staticmethod\n",
        "    def build_and_save_chunks(transcript_path, max_chars=1800, overlap_chars=200):\n",
        "        \"\"\"Main function to create and save chunks\"\"\"\n",
        "        print(f\"\\n=== Creating Chunks ===\")\n",
        "        doc_id = os.path.splitext(os.path.basename(transcript_path))[0]\n",
        "        sents_df = TextChunker.build_sentence_table(transcript_path)\n",
        "        chunks = TextChunker.make_chunks_from_sentences(sents_df, max_chars, overlap_chars)\n",
        "\n",
        "        out_rows = []\n",
        "        for i, c in enumerate(chunks):\n",
        "            out_rows.append({\n",
        "                \"doc_id\": doc_id,\n",
        "                \"chunk_idx\": i,\n",
        "                \"start_ts\": float(c[\"start_ts\"]),\n",
        "                \"end_ts\": float(c[\"end_ts\"]),\n",
        "                \"text\": c[\"text\"]\n",
        "            })\n",
        "\n",
        "        cdf = pd.DataFrame(out_rows)\n",
        "        outp = f\"{DATA}/chunks/{doc_id}_chunks.parquet\"\n",
        "        cdf.to_parquet(outp, index=False)\n",
        "        print(f\"✓ Chunks saved: {outp} ({len(cdf)} chunks)\")\n",
        "        return outp\n"
      ],
      "metadata": {
        "id": "V-2VYz8DEhzV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# VECTOR STORE CLASS\n",
        "# ========================================\n",
        "class VectorStore:\n",
        "    def __init__(self, collection_name=\"quantum_notes\", model_name='sentence-transformers/all-mpnet-base-v2'):\n",
        "        self.collection_name = collection_name\n",
        "        self.embedding_function = HuggingFaceEmbeddings(model_name=model_name)\n",
        "        self.persist_directory = \"./chroma_langchain_db\"\n",
        "\n",
        "        self.vector_store = Chroma(\n",
        "            collection_name=self.collection_name,\n",
        "            embedding_function=self.embedding_function,\n",
        "            persist_directory=self.persist_directory\n",
        "        )\n",
        "\n",
        "    def add_documents(self, docs):\n",
        "        \"\"\"Add documents to vector store\"\"\"\n",
        "        print(f\"\\n=== Adding {len(docs)} documents to vector store ===\")\n",
        "        self.vector_store.add_documents(docs)\n",
        "        print(\"✓ Documents added successfully\")\n",
        "\n",
        "    def similarity_search_with_score(self, query, k=5):\n",
        "        \"\"\"Search with similarity scores\"\"\"\n",
        "        results = self.vector_store.similarity_search_with_score(query, k=k)\n",
        "        results = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "        return results\n",
        "\n",
        "    def get_all_chunks(self):\n",
        "        \"\"\"Returns a list of Document objects\"\"\"\n",
        "        raw_data = self.vector_store.get()\n",
        "        docs = raw_data[\"documents\"]\n",
        "        metadatas = raw_data.get(\"metadatas\", [{}] * len(docs))\n",
        "\n",
        "        doc_objects = [Document(page_content=doc, metadata=meta) for doc, meta in zip(docs, metadatas)]\n",
        "        return doc_objects\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Clear the vector store\"\"\"\n",
        "        if os.path.exists(self.persist_directory):\n",
        "            shutil.rmtree(self.persist_directory)\n",
        "            print(f\"✓ Cleared vector store at {self.persist_directory}\")"
      ],
      "metadata": {
        "id": "o0s4FS13Em9r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# DOCUMENT SUMMARIZER CLASS\n",
        "# ========================================\n",
        "class DocumentSummarizer:\n",
        "    def __init__(self, model_name=\"llama-3.1-8b-instant\", use_groq=True):\n",
        "        \"\"\"\n",
        "        Initialize DocumentSummarizer\n",
        "\n",
        "        Args:\n",
        "            model_name: Model name to use\n",
        "            use_groq: If True, use Groq, else use OpenAI\n",
        "        \"\"\"\n",
        "        if use_groq:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "            self.llm = ChatGroq(model_name=model_name, verbose=False)\n",
        "        else:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_TOKEN\")\n",
        "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
        "\n",
        "    def summarize_all(self, chunks):\n",
        "        \"\"\"Summarize all chunks\"\"\"\n",
        "        print(\"\\n=== Summarizing All Chunks ===\")\n",
        "        chain = load_summarize_chain(self.llm, chain_type=\"map_reduce\")\n",
        "        summary = chain.invoke(chunks)\n",
        "        return summary\n",
        "\n",
        "    def summarize_query(self, vector_store, query, k=3):\n",
        "        \"\"\"Summarize based on query\"\"\"\n",
        "        print(f\"\\n=== Generating Summary for Query: '{query}' ===\")\n",
        "        results = vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"Based on the following context, provide a meaningful and insightful summary focusing on: {query}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "DO NOT make up stuff. If the text is empty or does not contain information related to the query, say 'Information not found in documents related to the query'\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        summary = self.llm.invoke(prompt.format(query=query, context=context))\n",
        "\n",
        "        return summary, relevant_docs\n",
        "\n",
        "    def summarize_notes(self, notes):\n",
        "        \"\"\"Summarize user-provided notes\"\"\"\n",
        "        print(\"\\n=== Summarizing Notes ===\")\n",
        "        prompt_template = \"\"\"Based on the given notes: {notes}, provide a meaningful and insightful summary.\n",
        "DO NOT make up stuff. If the notes are empty, say 'Notes not found!'\n",
        "Summary:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"notes\"])\n",
        "        summary = self.llm.invoke(prompt.format(notes=notes))\n",
        "        return summary"
      ],
      "metadata": {
        "id": "gXwRWQXTEr5K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# FLASHCARDS CLASS\n",
        "# ========================================\n",
        "class FlashCards:\n",
        "    def __init__(self, model_name=\"llama-3.1-8b-instant\", use_groq=True):\n",
        "        if use_groq:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API\")\n",
        "            self.llm = ChatGroq(model_name=model_name, verbose=False)\n",
        "        else:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_TOKEN\")\n",
        "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
        "\n",
        "    def create_flashcards_on_topic(self, vector_store, query, k=3):\n",
        "        \"\"\"Create flashcards on specific topic\"\"\"\n",
        "        print(f\"\\n=== Creating Flashcards for: '{query}' ===\")\n",
        "        results = vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert in creating flashcards based on the provided information.\n",
        "\n",
        "Based on the following context, create up to 8 flashcards focusing on the topic: {query}\n",
        "\n",
        "If the concept is complex, break it down into a core definition, formula, or key takeaway.\n",
        "\n",
        "Each flashcard should have:\n",
        "1. A question or term on one side\n",
        "2. A short (2 to 3 lines), memorable answer that captures the key point(s) on the other side\n",
        "3. Simple and erudite language that is easy to understand and memorize\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Format your response as:\n",
        "Front: [Question]\n",
        "Back: [Answer]\n",
        "\n",
        "Flashcards:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        formatted_prompt = prompt.format(query=query, context=context)\n",
        "        cards = self.llm.invoke(formatted_prompt)\n",
        "\n",
        "        return cards, relevant_docs\n",
        "\n",
        "    def create_flashcards_based_notes(self, notes):\n",
        "        \"\"\"Create flashcards from notes\"\"\"\n",
        "        print(\"\\n=== Creating Flashcards from Notes ===\")\n",
        "        prompt_template = \"\"\"You are an expert in creating flashcards based on the provided information.\n",
        "\n",
        "Based on the following notes, create up to 8 flashcards.\n",
        "notes: {notes}\n",
        "\n",
        "If the concept is complex, break it down into a core definition, formula, or key takeaway.\n",
        "\n",
        "Each flashcard should have:\n",
        "1. A question or term on one side\n",
        "2. A short (2 to 3 lines), memorable answer that captures the key point(s) on the other side\n",
        "3. Simple and erudite language that is easy to understand and memorize\n",
        "\n",
        "Format your response as:\n",
        "Front: [Question]\n",
        "Back: [Answer]\n",
        "\n",
        "Flashcards:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"notes\"]\n",
        "        )\n",
        "        cards = self.llm.invoke(prompt.format(notes=notes))\n",
        "        return cards"
      ],
      "metadata": {
        "id": "EB9XKK1tExRl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# QUIZ GENERATOR CLASS\n",
        "# ========================================\n",
        "class QuizGenerator:\n",
        "    def __init__(self, model_name=\"llama-3.1-8b-instant\", use_groq=True):\n",
        "        if use_groq:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "            self.llm = ChatGroq(model_name=model_name, verbose=False)\n",
        "        else:\n",
        "            if IN_COLAB:\n",
        "                os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_TOKEN\")\n",
        "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "\n",
        "    def generate_quiz_all(self, chunks, num_questions=10):\n",
        "        \"\"\"Generate quiz from all chunks\"\"\"\n",
        "        print(f\"\\n=== Generating Quiz ({num_questions} questions) ===\")\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in chunks[:15]])\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert quiz creator. Based on the following content, create a quiz with {num_questions} multiple-choice questions.\n",
        "\n",
        "Content:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "1. Create {num_questions} questions that test key concepts and understanding\n",
        "2. Each question should have 4 options (A, B, C, D)\n",
        "3. Mark the correct answer\n",
        "4. Cover different topics/concepts from the content\n",
        "5. Mix difficulty levels (easy, medium, hard)\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Question 1: [Question text]\n",
        "A) [Option A]\n",
        "B) [Option B]\n",
        "C) [Option C]\n",
        "D) [Option D]\n",
        "Correct Answer: [A/B/C/D]\n",
        "Explanation: [Brief explanation of why this is correct]\n",
        "\n",
        "[Continue for all {num_questions} questions]\n",
        "\n",
        "Quiz:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"num_questions\", \"context\"]\n",
        "        )\n",
        "\n",
        "        quiz = self.llm.invoke(prompt.format(num_questions=num_questions, context=context))\n",
        "        print(\"✓ Quiz generation complete!\")\n",
        "        return quiz\n",
        "\n",
        "    def generate_quiz_on_topic(self, vector_store, query, num_questions=10, k=5):\n",
        "        \"\"\"Generate quiz on specific topic\"\"\"\n",
        "        print(f\"\\n=== Generating Quiz on Topic: '{query}' ({num_questions} questions) ===\")\n",
        "        results = vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert quiz creator. Based on the following context, create a quiz with {num_questions} multiple-choice questions focusing on: {query}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "1. Create {num_questions} questions specifically about: {query}\n",
        "2. Each question should have 4 options (A, B, C, D)\n",
        "3. Mark the correct answer\n",
        "4. Questions should test understanding of the topic\n",
        "5. Mix difficulty levels (easy, medium, hard)\n",
        "\n",
        "DO NOT make up information. If the context doesn't contain enough information about the query, create fewer questions and mention: \"Limited information available for full quiz on this topic.\"\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Question 1: [Question text]\n",
        "A) [Option A]\n",
        "B) [Option B]\n",
        "C) [Option C]\n",
        "D) [Option D]\n",
        "Correct Answer: [A/B/C/D]\n",
        "Explanation: [Brief explanation]\n",
        "\n",
        "[Continue for all questions]\n",
        "\n",
        "Quiz:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"num_questions\", \"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        quiz = self.llm.invoke(\n",
        "            prompt.format(num_questions=num_questions, query=query, context=context)\n",
        "        )\n",
        "\n",
        "        print(\"✓ Quiz generation complete!\")\n",
        "        return quiz, relevant_docs\n",
        "\n",
        "    def generate_quiz_from_notes(self, notes, num_questions=10):\n",
        "        \"\"\"Generate quiz from notes\"\"\"\n",
        "        print(f\"\\n=== Generating Quiz from Notes ({num_questions} questions) ===\")\n",
        "        prompt_template = \"\"\"You are an expert quiz creator. Based on the given notes, create a quiz with {num_questions} multiple-choice questions.\n",
        "\n",
        "Notes:\n",
        "{notes}\n",
        "\n",
        "Instructions:\n",
        "1. Create {num_questions} questions that test understanding of the notes\n",
        "2. Each question should have 4 options (A, B, C, D)\n",
        "3. Mark the correct answer\n",
        "4. Cover key concepts from the notes\n",
        "5. Mix difficulty levels (easy, medium, hard)\n",
        "\n",
        "DO NOT make up stuff. If the notes are empty or too short, say 'Notes insufficient for quiz generation!'\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Question 1: [Question text]\n",
        "A) [Option A]\n",
        "B) [Option B]\n",
        "C) [Option C]\n",
        "D) [Option D]\n",
        "Correct Answer: [A/B/C/D]\n",
        "Explanation: [Brief explanation]\n",
        "\n",
        "[Continue for all {num_questions} questions]\n",
        "\n",
        "Quiz:\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"num_questions\", \"notes\"]\n",
        "        )\n",
        "\n",
        "        quiz = self.llm.invoke(prompt.format(num_questions=num_questions, notes=notes))\n",
        "        print(\"✓ Quiz generation complete!\")\n",
        "        return quiz"
      ],
      "metadata": {
        "id": "KeMy-Sn8E2cc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# MAIN PIPELINE CLASS\n",
        "# ========================================\n",
        "class QuantumNotesPipeline:\n",
        "    \"\"\"\n",
        "    Main pipeline for QuantumNotes with multimodal support\n",
        "\n",
        "    Supports:\n",
        "    - Videos (mp4, mkv, mov, avi)\n",
        "    - Audio (wav, mp3, m4a, flac, aac, ogg)\n",
        "    - PDFs\n",
        "    - Text files\n",
        "    - Transcripts (txt, srt, vtt, json, parquet)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_groq=True):\n",
        "        \"\"\"\n",
        "        Initialize pipeline\n",
        "\n",
        "        Args:\n",
        "            use_groq: If True, use Groq for LLM, else use OpenAI\n",
        "        \"\"\"\n",
        "        self.file_processor = FileProcessor()\n",
        "        self.use_groq = use_groq\n",
        "        self.vector_store = None\n",
        "        self.current_doc_id = None\n",
        "\n",
        "    def process_file(self, file_path):\n",
        "        \"\"\"\n",
        "        Process any supported file type\n",
        "\n",
        "        Args:\n",
        "            file_path: Path to the file\n",
        "\n",
        "        Returns:\n",
        "            VectorStore instance ready for querying\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"QUANTUMNOTES MULTIMODAL PIPELINE\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Step 1: Process file (video/audio/pdf/transcript)\n",
        "        transcript_path = self.file_processor.route_file(file_path)\n",
        "        self.current_doc_id = self.file_processor.get_file_stem(file_path)\n",
        "\n",
        "        # Step 2: Create chunks\n",
        "        chunks_path = TextChunker.build_and_save_chunks(\n",
        "            transcript_path,\n",
        "            max_chars=CHUNK_SIZE,\n",
        "            overlap_chars=CHUNK_OVERLAP\n",
        "        )\n",
        "\n",
        "        # Step 3: Load chunks as documents\n",
        "        df = pd.read_parquet(chunks_path)\n",
        "        documents = [\n",
        "            Document(\n",
        "                page_content=row[\"text\"],\n",
        "                metadata={\n",
        "                    \"doc_id\": row[\"doc_id\"],\n",
        "                    \"chunk_idx\": row[\"chunk_idx\"],\n",
        "                    \"start_ts\": row[\"start_ts\"],\n",
        "                    \"end_ts\": row[\"end_ts\"]\n",
        "                }\n",
        "            ) for _, row in df.iterrows()\n",
        "        ]\n",
        "\n",
        "        # Step 4: Create vector store\n",
        "        print(f\"\\n=== Building Vector Store ===\")\n",
        "        self.vector_store = VectorStore(collection_name=f\"quantum_{self.current_doc_id}\")\n",
        "        self.vector_store.add_documents(documents)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"✓ File processing complete!\")\n",
        "        print(f\"✓ Document ID: {self.current_doc_id}\")\n",
        "        print(f\"✓ Total chunks: {len(documents)}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        return self.vector_store\n",
        "\n",
        "    def summarize(self, query=None, k=3):\n",
        "        \"\"\"Generate summary based on query or summarize all\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        ds = DocumentSummarizer(use_groq=self.use_groq)\n",
        "\n",
        "        if query:\n",
        "            summary, relevant_docs = ds.summarize_query(self.vector_store, query, k=k)\n",
        "            return summary, relevant_docs\n",
        "        else:\n",
        "            all_chunks = self.vector_store.get_all_chunks()\n",
        "            summary = ds.summarize_all(all_chunks)\n",
        "            return summary\n",
        "\n",
        "\n",
        "    def summarize_all(self):\n",
        "        \"\"\"Summarize entire document\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        ds = DocumentSummarizer(use_groq=self.use_groq)\n",
        "        all_chunks = self.vector_store.get_all_chunks()\n",
        "        summary = ds.summarize_all(all_chunks)\n",
        "        return summary\n",
        "\n",
        "    def make_notes(self, query, k=3):\n",
        "        \"\"\"Create structured notes\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        # Use summarizer to generate notes-style content\n",
        "        ds = DocumentSummarizer(use_groq=self.use_groq)\n",
        "        results = self.vector_store.similarity_search_with_score(query)\n",
        "        relevant_docs = [doc for doc, score in results[:k]]\n",
        "\n",
        "        prompt_template = \"\"\"You are an expert in analyzing documents and creating meaningful notes.\n",
        "\n",
        "Based on the following text:\n",
        "{context}\n",
        "\n",
        "Create structured notes focusing on the query: {query}\n",
        "\n",
        "These notes should have:\n",
        "1. Key Points: [main ideas]\n",
        "2. Important Details: [supporting information]\n",
        "3. Actionable Insights: [what can be done]\n",
        "4. Additional Information: [any other relevant details from the text]\"\"\"\n",
        "\n",
        "        prompt = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"query\", \"context\"]\n",
        "        )\n",
        "\n",
        "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_docs])\n",
        "        notes = ds.llm.invoke(prompt.format(query=query, context=context))\n",
        "\n",
        "        return notes\n",
        "\n",
        "    def create_flashcards(self, query, k=3):\n",
        "        \"\"\"Generate flashcards on topic\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        fc = FlashCards(use_groq=self.use_groq)\n",
        "        cards, relevant_docs = fc.create_flashcards_on_topic(self.vector_store, query, k=k)\n",
        "        return cards, relevant_docs\n",
        "\n",
        "    def generate_quiz(self, query=None, num_questions=10, k=5):\n",
        "        \"\"\"Generate quiz\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        qg = QuizGenerator(use_groq=self.use_groq)\n",
        "\n",
        "        if query:\n",
        "            quiz, relevant_docs = qg.generate_quiz_on_topic(\n",
        "                self.vector_store,\n",
        "                query,\n",
        "                num_questions=num_questions,\n",
        "                k=k\n",
        "            )\n",
        "            return quiz, relevant_docs\n",
        "        else:\n",
        "            all_chunks = self.vector_store.get_all_chunks()\n",
        "            quiz = qg.generate_quiz_all(all_chunks, num_questions=num_questions)\n",
        "            return quiz\n",
        "\n",
        "\n",
        "    def search(self, query, k=5):\n",
        "        \"\"\"Search for relevant chunks\"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No file processed. Call process_file() first.\")\n",
        "\n",
        "        results = self.vector_store.similarity_search_with_score(query, k=k)\n",
        "        return results"
      ],
      "metadata": {
        "id": "Pn4HABqjFFDT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "\n",
        "file_path = \"/content/MCAKCA032-PRINCIPALES OF SOFT COMPUTING-SN SIVNANDAM AND DEEPA SN (1).pdf\"\n",
        "pipeline.process_file(file_path)\n",
        "\n",
        "summary = pipeline.summarize(\"What is Linear Vector Quantization?\")\n",
        "print(summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3z7igKCFL0C",
        "outputId": "2d54c985-926c-4d44-bb50-b3b3a7185db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "QUANTUMNOTES MULTIMODAL PIPELINE\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Processing file: MCAKCA032-PRINCIPALES OF SOFT COMPUTING-SN SIVNANDAM AND DEEPA SN (1).pdf\n",
            "File type: .pdf\n",
            "============================================================\n",
            "\n",
            "=== Processing PDF ===\n",
            "✓ PDF processed: ./data/transcripts/MCAKCA032-PRINCIPALES_OF_SOFT_COMPUTING-SN_SIVNANDAM_AND_DEEPA_SN__1.parquet\n",
            "\n",
            "=== Creating Chunks ===\n",
            "✓ Chunks saved: ./data/chunks/MCAKCA032-PRINCIPALES_OF_SOFT_COMPUTING-SN_SIVNANDAM_AND_DEEPA_SN__1_chunks.parquet (786 chunks)\n",
            "\n",
            "=== Building Vector Store ===\n",
            "\n",
            "=== Adding 786 documents to vector store ===\n",
            "✓ Documents added successfully\n",
            "\n",
            "============================================================\n",
            "✓ File processing complete!\n",
            "✓ Document ID: MCAKCA032-PRINCIPALES_OF_SOFT_COMPUTING-SN_SIVNANDAM_AND_DEEPA_SN__1\n",
            "✓ Total chunks: 786\n",
            "============================================================\n",
            "\n",
            "\n",
            "=== Generating Summary for Query: 'What is Linear Vector Quantization?' ===\n",
            "Information not found in documents related to the query\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "file_path = \"/content/ana-bell-v1.mp3\"\n",
        "pipeline.process_file(file_path)\n",
        "summary, relevant_docs = pipeline.summarize(\"Key concepts\")\n",
        "print(summary.content)\n",
        "print(\"\\nRelevant Documents:\")\n",
        "for doc in relevant_docs:\n",
        "    print(f\"- {doc.page_content[:200]}...\") # Print first 200 characters of each doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgYg3TBMFmAW",
        "outputId": "467519cf-c7b7-49ea-d85d-51631a2783e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "QUANTUMNOTES MULTIMODAL PIPELINE\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Processing file: ana-bell-v1.mp3\n",
            "File type: .mp3\n",
            "============================================================\n",
            "\n",
            "=== Processing Audio ===\n",
            "Converting .mp3 to WAV...\n",
            "✓ Audio ready: ./data/audio/ana-bell-v1.wav\n",
            "Initializing Whisper model...\n",
            "Transcribing audio: ./data/audio/ana-bell-v1.wav\n",
            "✓ Transcript saved: ./data/transcripts/ana-bell-v1.parquet\n",
            "\n",
            "=== Creating Chunks ===\n",
            "✓ Chunks saved: ./data/chunks/ana-bell-v1_chunks.parquet (16 chunks)\n",
            "\n",
            "=== Building Vector Store ===\n",
            "\n",
            "=== Adding 16 documents to vector store ===\n",
            "✓ Documents added successfully\n",
            "\n",
            "============================================================\n",
            "✓ File processing complete!\n",
            "✓ Document ID: ana-bell-v1\n",
            "✓ Total chunks: 16\n",
            "============================================================\n",
            "\n",
            "\n",
            "=== Generating Summary for Query: 'Key concepts' ===\n",
            "Key concepts discussed in the given context include:\n",
            "\n",
            "1. **Interpretation**: The importance of understanding that programming code can be interpreted in only one way, unlike human language where multiple interpretations are possible.\n",
            "\n",
            "2. **Rubber Duckie Debugging**: A technique used to debug code by explaining the code to an inanimate object, such as a rubber duck, to identify and correct errors.\n",
            "\n",
            "3. **Active Learning**: Encouraging students to start coding from a blank slate, rather than just following instructions, to improve their understanding and coding skills.\n",
            "\n",
            "4. **Growth Mindset**: The idea that programming skills can be developed through practice, trying new things, and challenging oneself, rather than being a natural ability.\n",
            "\n",
            "5. **Perfectionism vs. Practice**: Emphasizing the importance of de-emphasizing perfection and focusing on practice, allowing students to learn from their mistakes and improve their skills.\n",
            "\n",
            "6. **Creative Problem-Solving**: The value of taking time away from a problem and explaining it to someone else or an inanimate object to find creative solutions.\n",
            "\n",
            "Relevant Documents:\n",
            "- somebody else can interpret it however they'd like. One example we give to students is the chicken is ready to eat. What do you think about when I say the chicken is ready to eat? Well, I'm a vegetari...\n",
            "- And then in the actual classroom, we do active learning. So, I go over maybe something that's a little bit more confusing, and then I give them time to break. With the hope that me forcing them to hav...\n",
            "- And then in the actual classroom, we do active learning. So, I go over maybe something that's a little bit more confusing, and then I give them time to break. With the hope that me forcing them to hav...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "cards, relevant_docs = pipeline.create_flashcards(\"Important terms\")\n",
        "print(cards.content)\n",
        "print(\"\\nRelevant Documents:\")\n",
        "for doc in relevant_docs:\n",
        "    print(f\"- {doc.page_content[:200]}...\") # Print first 200 characters of each doc"
      ],
      "metadata": {
        "id": "V9bCHt3hFrhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "file_path = \"/content/lecture_transcript.txt\"\n",
        "pipeline.process_file(file_path)\n",
        "quiz, relevant_docs = pipeline.generate_quiz(\"Core concepts\", num_questions=5)\n",
        "print(quiz.content)\n",
        "print(\"\\nRelevant Documents:\")\n",
        "for doc in relevant_docs:\n",
        "    print(f\"- {doc.page_content[:100]}...\") # Print first 200 characters of each doc"
      ],
      "metadata": {
        "id": "ZLYfeOAtFxMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f7c81d-672c-486e-b22d-334110a8d05a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "QUANTUMNOTES MULTIMODAL PIPELINE\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Processing file: lecture_transcript.txt\n",
            "File type: .txt\n",
            "============================================================\n",
            "\n",
            "=== Processing Transcript File ===\n",
            "✓ Transcript saved: ./data/transcripts/lecture_transcript.parquet\n",
            "\n",
            "=== Creating Chunks ===\n",
            "✓ Chunks saved: ./data/chunks/lecture_transcript_chunks.parquet (17 chunks)\n",
            "\n",
            "=== Building Vector Store ===\n",
            "\n",
            "=== Adding 17 documents to vector store ===\n",
            "✓ Documents added successfully\n",
            "\n",
            "============================================================\n",
            "✓ File processing complete!\n",
            "✓ Document ID: lecture_transcript\n",
            "✓ Total chunks: 17\n",
            "============================================================\n",
            "\n",
            "\n",
            "=== Generating Quiz on Topic: 'Core concepts' (5 questions) ===\n",
            "✓ Quiz generation complete!\n",
            "Question 1: What is the primary purpose of MIT OpenCourseWare (OCW)?\n",
            "A) To provide exclusive educational resources to MIT students only\n",
            "B) To share transformational resources with a wider audience\n",
            "C) To create a community for MIT professors to discuss course materials\n",
            "D) To sell online courses for a fee\n",
            "Correct Answer: B) To share transformational resources with a wider audience\n",
            "Explanation: The text suggests that MIT OCW aims to help others discover transformational resources.\n",
            "\n",
            "Question 2: Who funded Chalk Radio?\n",
            "A) MIT Open Learning\n",
            "B) Cambridge University\n",
            "C) Supporters like the audience\n",
            "D) Chalk Radio's producers\n",
            "Correct Answer: A) MIT Open Learning\n",
            "Explanation: The text explicitly states that Chalk Radio is funded by MIT Open Learning and supporters like the audience.\n",
            "\n",
            "Question 3: What is the name of the podcast host mentioned in the text?\n",
            "A) Brett Paci\n",
            "B) Dave Leshansky\n",
            "C) Jackson Maher\n",
            "D) Sarah Hanson\n",
            "Correct Answer: D) Sarah Hanson\n",
            "Explanation: The text clearly states that the podcast is hosted by Sarah Hanson.\n",
            "\n",
            "Question 4: Limited information available for full quiz on this topic.\n",
            "\n",
            "However, I can create one question about the location mentioned in the text:\n",
            " Question 1: Where is the host signing off from?\n",
            "A) Boston, Massachusetts\n",
            "B) Cambridge, Massachusetts\n",
            "C) New York City, New York\n",
            "D) Washington D.C.\n",
            "Correct Answer: B) Cambridge, Massachusetts\n",
            "Explanation: The text explicitly states that the host is signing off from Cambridge, Massachusetts.\n",
            "\n",
            "Here are the remaining questions:\n",
            " Question 5: What is the name of the YouTube channel where the interview can be found?\n",
            "A) MIT OCW\n",
            "B) YouTube\n",
            "C) Chalk Radio\n",
            "D) MIT OpenCourseWare\n",
            "Correct Answer: A) MIT OCW\n",
            "Explanation: The text provides the YouTube handle for MIT OCW.\n",
            "\n",
            "Relevant Documents:\n",
            "- If you love what you find, help others discover these transformational resources by subscribing to o...\n",
            "- If you love what you find, help others discover these transformational resources by subscribing to o...\n",
            "- If you love what you find, help others discover these transformational resources by subscribing to o...\n",
            "- If you love what you find, help others discover these transformational resources by subscribing to o...\n",
            "- If you love what you find, help others discover these transformational resources by subscribing to o...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = QuantumNotesPipeline(use_groq=True)\n",
        "results = pipeline.search(\"specific topic\", k=3)\n",
        "for doc, score in results:\n",
        "      print(f\"Score: {score}\")\n",
        "      print(doc.page_content)\n",
        "      print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "1pEomXUxF7Fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}